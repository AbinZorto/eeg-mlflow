# MAXIMUM GPU UTILIZATION Configuration for Dual RTX 3090
# Push the hardware to its absolute limits

# Data Configuration
data:
  feature_path: "data/processed/features/2s_window_features.parquet"
  split:
    test_size: 0.2
    random_state: 42
    stratify: true

# Model Configuration - MAXIMUM GPU utilization
model_type: "pytorch_mlp" # GPU-optimized model

model:
  name: "patient_model_max_gpu"

  params:
    random_forest:
      n_estimators: 200
      min_samples_leaf: 2
      max_features: "sqrt"
      class_weight: "balanced"
      random_state: 42

# MAXIMUM GPU Configuration - Push RTX 3090s to the limit
deep_learning:
  pytorch_mlp:
    hidden_layers: [2048, 1024, 512, 256, 128] # MASSIVE network - 5 layers
    dropout_rate: 0.05 # Very minimal dropout for maximum computation
    weight_decay: 0.00001 # Minimal weight decay
    learning_rate: 0.1 # VERY aggressive learning rate
    batch_size: 4096 # ENORMOUS batch size - should use most VRAM
    epochs: 30 # Fewer epochs but each epoch does massive work
    early_stopping_patience: 5 # Very aggressive early stopping
    batch_norm: true
    activation: "relu"
    optimizer: "adam"
    class_weight: "balanced"
    random_state: 42

  keras_mlp:
    hidden_layers: [2048, 1024, 512, 256, 128] # MASSIVE network
    dropout_rate: 0.05
    l1_reg: 0.000001 # Virtually no regularization
    l2_reg: 0.00001 # Virtually no regularization  
    learning_rate: 0.1 # VERY aggressive learning rate
    batch_size: 4096 # ENORMOUS batch size
    epochs: 30 # Fewer epochs
    early_stopping_patience: 5
    batch_norm: true
    activation: "relu"
    optimizer: "adam"
    class_weight: "balanced"
    random_state: 42

# Paths Configuration
paths:
  models: "models/window_level"
  features: "data/processed/features"
  logs: "logs"

# Output Configuration
output:
  save_predictions: true
  save_probabilities: true
  feature_importance: true
  performance_plots: true

# MLflow Tracking
mlflow:
  experiment_name: "window_training_max_gpu"
  tracking_uri: "file:./mlruns"
  register_model: true
  model_stage: "Development"
  artifact_location: "./mlruns"

# Evaluation Metrics
metrics:
  window_level:
    - accuracy
    - precision
    - recall
    - f1
    - roc_auc
  patient_level:
    - accuracy
    - precision
    - recall
    - f1
    - roc_auc

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/window_training_max_gpu.log"
  console: true 